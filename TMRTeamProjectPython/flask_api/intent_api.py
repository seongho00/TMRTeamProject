from flask import Flask, request, jsonify, Response
import json
import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pickle
import re
import mecab_ko

tagger = mecab_ko.Tagger()
print(tagger.parse("ëŒ€ì „ì— ìˆëŠ” ìœ ì„±êµ¬ì˜ ìœ ë™ì¸êµ¬ ì•Œë ¤ì¤˜"))

app = Flask(__name__)

# âœ… intent label ë³µì› (ë¼ë²¨ ì¸ì½”ë”ë¡œ)
with open("label_encoder.pickle", "rb") as f:
    label_encoder = pickle.load(f)
intent_labels = list(label_encoder.classes_)

# âœ… HuggingFace BERT ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
MODEL_PATH = "./intent_bert_model"
tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)
model = BertForSequenceClassification.from_pretrained(MODEL_PATH)
model.eval()


# âœ… ì˜ˆì¸¡ í•¨ìˆ˜
def predict_intent(text, threshold=0.1):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=32)

    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = torch.nn.functional.softmax(logits, dim=1)[0]
        confidence, predicted_class_id = torch.max(probs, dim=0)

    confidence = confidence.item()
    class_idx = predicted_class_id.item()

    if confidence < threshold:
        return "ì§€ì›í•˜ì§€ ì•ŠëŠ” ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.", confidence

    predicted_label = label_encoder.inverse_transform([class_idx])[0]
    return predicted_label, confidence


def extract_location(text):
    valid_city_map = {
        'ëŒ€ì „': ['ì„œêµ¬', 'ìœ ì„±êµ¬', 'ëŒ€ë•êµ¬', 'ë™êµ¬', 'ì¤‘êµ¬']
    }
    # ì‹œë„ + ì‹œêµ°êµ¬ + ìë©´ë™ê¹Œì§€ ì¶”ì¶œ
    pattern = r"(ì„œìš¸|ë¶€ì‚°|ëŒ€êµ¬|ì¸ì²œ|ê´‘ì£¼|ëŒ€ì „|ìš¸ì‚°|ì„¸ì¢…|ê²½ê¸°|ê°•ì›|ì¶©ë¶|ì¶©ë‚¨|ì „ë¶|ì „ë‚¨|ê²½ë¶|ê²½ë‚¨|ì œì£¼)[\s]*(?:íŠ¹ë³„ì‹œ|ê´‘ì—­ì‹œ|ë„)?[\s]*" \
              r"([ê°€-í£]+[ì‹œêµ°êµ¬])?[\s]*([ê°€-í£]+[ë™ë©´ì])?"

    match = re.search(pattern, text)
    if match:
        sido, sigungu, eupmyeondong = match.groups()
        if sigungu and sigungu not in valid_city_map.get(sido, []):
            return "âŒ í–‰ì •êµ¬ì—­ í˜•ì‹ì— ë§ì§€ ì•ŠìŒ"  # âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì¡°í•©
        parts = [sido, sigungu, eupmyeondong]
        return " ".join(p for p in parts if p)

    return None


# âœ… ì˜ë„ + ì§€ì—­ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
def generate_response(user_input):
    intent, confidence = predict_intent(user_input)
    location = extract_location(user_input)

    if intent == 0:
        if location:
            return f"âœ… '{location}'ì˜ ë§¤ì¶œ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."
        else:
            return "âš ï¸ ë§¤ì¶œ ì •ë³´ë¥¼ ì¡°íšŒí•˜ë ¤ë©´ ì§€ì—­ëª…ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”."

    elif intent == 1:
        if location:
            return f"ğŸ“Š '{location}'ì˜ ì¸êµ¬ í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."
        else:
            return "âš ï¸ ì¸êµ¬ ì •ë³´ë¥¼ ì¡°íšŒí•˜ë ¤ë©´ ì§€ì—­ëª…ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”."

    elif intent == 2:
        return "ğŸš¨ íì—… ìœ„í—˜ë„ ë†’ì€ ìƒê¶Œì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤."

    else:
        return "â“ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤."


# âœ… ëª…ì‚¬ë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
def extract_nouns(text):
    parsed = tagger.parse(text)
    lines = parsed.split('\n')
    nouns = []

    for line in lines:
        if line == 'EOS' or line == '':
            continue
        word, feature = line.split('\t')
        pos = feature.split(',')[0]

        if pos in ['NNG', 'NNP']:  # ì¼ë°˜ëª…ì‚¬ or ê³ ìœ ëª…ì‚¬
            nouns.append(word)

    return nouns

# âœ… ì˜ë¯¸ ë¶„ì„ í•¨ìˆ˜
def analyze_input(user_input):
    valid_city_map = {
        'ëŒ€ì „': ['ì„œêµ¬', 'ìœ ì„±êµ¬', 'ëŒ€ë•êµ¬', 'ë™êµ¬', 'ì¤‘êµ¬']
    }

    gender_keywords = {
        "ë‚¨ì": "male", "ë‚¨ì„±": "male",
        "ì—¬ì": "female", "ì—¬ì„±": "female"
    }

    age_keywords = {
        "10ëŒ€": "age_10",
        "20ëŒ€": "age_20",
        "30ëŒ€": "age_30",
        "40ëŒ€": "age_40",
        "50ëŒ€": "age_50",
        "60ëŒ€": "age_60"
    }

    nouns = extract_nouns(user_input)

    gender = None
    age_group = None
    sido = None
    sigungu = None

    for token in nouns:
        for city in valid_city_map:
            if token.startswith(city):
                sido = city
        if sido and token in valid_city_map[sido]:
            sigungu = token
        if token in gender_keywords:
            gender = gender_keywords[token]
        if token in age_keywords:
            age_group = age_keywords[token]

    return gender, age_group, sido, sigungu

# âœ… API ë¼ìš°íŒ…
@app.route("/predict", methods=["GET"])
def predict():
    question = request.args.get("text", "").strip()

    if not question:
        return jsonify({"error": "text íŒŒë¼ë¯¸í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."}), 400

    # ì˜ˆì¸¡
    intent, confidence = predict_intent(question)

    # ë©”ì„¸ì§€
    message = generate_response(question)

    # âœ… ì„±ë³„, ì—°ë ¹, ì§€ì—­ ëª¨ë‘ ì¶”ì¶œ (MeCab ê¸°ë°˜)
    gender, age_group, sido, sigungu = analyze_input(question)


    return Response(
        json.dumps({
            "intent": str(intent),
            "confidence": float(round(confidence, 4)),
            "sido": str(sido),
            "sigungu": str(sigungu),
            "gender": str(gender),
            "age_group": str(age_group),
            "message": str(message)
        }, ensure_ascii=False),
        content_type="application/json; charset=utf-8"
    )



if __name__ == "__main__":
    app.run(port=5000, debug=True)
